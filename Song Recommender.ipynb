{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rcommending Songs with Content Based Filtering**\n",
    "\n",
    "Knowing features about items and user preferences over a subset of those items, how can we recommend other items that each user is most likely to enjoy? Recommended content drives everything from ad placement on web properties like Twitter and Facebook to songs in Spotify, movies on NetFlix and goods to buy on Amazon.  Its been shown by these businesses and others that recommendations drive user engagement and ultimately growth. Therefore, approaches to recommendations have garnered sigificant interest within both academia and industry. \n",
    "\n",
    "\n",
    "**Content Based Filtering**\n",
    "\n",
    "Our input data consists of two matrices. One repsenting song features and the other presenting user preferences. \n",
    "\n",
    "$S \\, \\sim [n \\, songs, m \\,features] \\\\\n",
    "U \\, \\sim [n \\, songs, k \\, users]$\n",
    "\n",
    "Our goal to to generate user profile vectors that reflect the relationship between user song preferences and the song-features. These vectors will then enable use to infer the probability of a user liking as yet unlistened songs. \n",
    "\n",
    "\n",
    "** Song-Feature Transformation **\n",
    "\n",
    "The raw feature conts per song are not suffiient for usage in recommending songs. Features that are highly common to many songs will dominate while features that are unique to a small number of songs won't be able to provide a unique \"fingerprint\" for each song. \n",
    "\n",
    "To overcome this problem, we can realize that S is very similar to a Bag of Words vector space model. The canonical approach to normalize raw feature counts is to use Term Frequeny - Inverse Document Frequency transformaton (TF-IDF) of S. The mathematical underpinnings of TF-IDF are well documented (e.g. https://en.wikipedia.org/wiki/Tf%E2%80%93idf) and we will not cover them here. Here we have a simplified case in that S is a binary matrix, where a song either had or doesn't have a feature. Due to this, we need to be aware of divide by zero issues and will use an add-1 smoothing procedure as a workaround. \n",
    "\n",
    "\n",
    "$ T \\sim \\mathrm{tfidf}(f,s,S) = \\mathrm{tf}(f,s) \\times \\mathrm{idf}(f, S) \\\\\n",
    "\\text {with s: songs and f: features} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** User profile generation **\n",
    "\n",
    "To generate user profiles, $ P $,  relating user prefences, $ U $, to normalized song features, $ T $, we mutiply the transpose of T by U.\n",
    "\n",
    "$P = T^\\top U $\n",
    "\n",
    "** Recommendations **\n",
    "\n",
    "With user profiles in hand, we can now generate recommedations, $ R $, based on the likelihood of a user liking the new song. To avoid recommending songs the user has already liked or disliked, we generate a mask from $ U $ to force the lieklihood of previously listened songs to a negative value. We then sort the resulting likelihood per song per user and select the top N songs to recommend per user. \n",
    " \n",
    "$ M = U_{not listened} \\\\\n",
    "R = TP \\circ M \\, (\\circ \\, \\text{denotes element wise)} $\n",
    "\n",
    "\n",
    "This results in a (n song x 1) vector that repsents the $ \\sim L(like_{user}|song) $\n",
    "\n",
    "We can sort this vector on likelihood and select the top N to present to the user. Based on user behavior we can subsequently compare the actual like to predicted like to determine the efficacy of the model. More feedback from the users can over time be further leverage in the same way we do here but imporove the efficacy due to an increase in the number of observations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let's do it :) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using data path: /Users/jonathan/Documents/Repos/song_recs/data\n",
      "loaded /Users/jonathan/Documents/Repos/song_recs/data/song_features.csv\n",
      "loaded /Users/jonathan/Documents/Repos/song_recs/data/user_prefs.csv\n",
      "transformed song and user preference data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'User 1': [('song12', 2.1297548364159167),\n",
       "  ('song24', 1.1905278193536848),\n",
       "  ('song9', 1.0785253727096404),\n",
       "  ('song3', 0.89584169671185554),\n",
       "  ('song18', 0.86531630469769871)],\n",
       " 'User 2': [('song7', 2.4828688452783267),\n",
       "  ('song13', 2.3069838721405587),\n",
       "  ('song14', 1.8355991980975666),\n",
       "  ('song8', 1.4869277170756716),\n",
       "  ('song15', 1.4023537675344044)]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from song_recs.song_reccomender import SongRecommender\n",
    "\n",
    "sr = SongRecommender()\n",
    "recs = {}\n",
    "recs[\"User 1\"] = sr.recommend(\"User 1\",n_songs=5)\n",
    "recs[\"User 2\"] = sr.recommend(\"User 2\",n_songs=5)\n",
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
